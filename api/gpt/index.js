// Vercel Serverless Function for GPT API proxy
module.exports = async (req, res) => {
  // Enable CORS
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'OPTIONS') {
    res.status(200).end();
    return;
  }

  // æ”¯æ´ GET è«‹æ±‚ç”¨æ–¼æ¸¬è©¦
  if (req.method === 'GET') {
    return res.status(200).json({
      message: 'GPT API is working!',
      method: 'GET',
      timestamp: new Date().toISOString(),
      hasOpenAIKey: !!process.env.OPENAI_API_KEY,
      usage: 'Send POST request with { "prompt": "your question" }'
    });
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  try {
    const { prompt, systemPrompt, model = 'gpt-3.5-turbo' } = req.body;

    if (!prompt) {
      return res.status(400).json({ error: 'Prompt is required' });
    }

    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      console.error('âŒ OpenAI API key not configured');
      return res.status(500).json({ 
        error: 'OpenAI API key not configured',
        message: 'Please configure OPENAI_API_KEY in Vercel environment variables'
      });
    }

    const messages = [];
    if (systemPrompt) {
      messages.push({ role: 'system', content: systemPrompt });
    }
    messages.push({ role: 'user', content: prompt });

    // è¨˜éŒ„è«‹æ±‚ä¿¡æ¯ï¼ˆä¸è¨˜éŒ„å®Œæ•´å…§å®¹ä»¥é¿å…æ—¥èªŒéé•·ï¼‰
    console.log(`ğŸ“¤ Sending request to OpenAI:`, {
      model,
      messagesCount: messages.length,
      promptLength: prompt.length,
      systemPromptLength: systemPrompt ? systemPrompt.length : 0
    });

    const requestBody = {
      model,
      messages,
      temperature: 0.7,
      max_tokens: 4000, // å¢åŠ æœ€å¤§tokenæ•¸ï¼Œç¢ºä¿ç­”æ¡ˆæ›´è©³ç´°
      top_p: 0.9,
      frequency_penalty: 0.3,
      presence_penalty: 0.3
    };

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
      let errorData;
      try {
        errorData = await response.json();
      } catch (parseError) {
        errorData = { 
          error: { 
            message: `HTTP ${response.status}: ${response.statusText}`,
            type: 'unknown_error'
          }
        };
      }
      
      console.error('âŒ OpenAI API error:', {
        status: response.status,
        statusText: response.statusText,
        error: errorData
      });

      // æ ¹æ“šä¸åŒçš„éŒ¯èª¤é¡å‹è¿”å›æ›´è©³ç´°çš„ä¿¡æ¯
      let errorMessage = 'OpenAI API error';
      if (errorData.error) {
        if (errorData.error.message) {
          errorMessage = errorData.error.message;
        } else if (typeof errorData.error === 'string') {
          errorMessage = errorData.error;
        }
      }

      return res.status(response.status).json({ 
        error: errorMessage,
        details: errorData,
        status: response.status
      });
    }

    const data = await response.json();
    const content = data.choices?.[0]?.message?.content?.trim() || 'âš ï¸ ç„¡æ³•å–å¾—å›æ‡‰';

    console.log(`âœ… Successfully received response from OpenAI (${content.length} characters)`);

    res.status(200).json({ content });

  } catch (error) {
    console.error('âŒ GPT API proxy error:', {
      name: error.name,
      message: error.message,
      stack: error.stack
    });
    
    // è¿”å›æ›´è©³ç´°çš„éŒ¯èª¤ä¿¡æ¯
    res.status(500).json({ 
      error: 'Internal server error',
      message: error.message,
      type: error.name || 'UnknownError',
      details: process.env.NODE_ENV === 'development' ? error.stack : undefined
    });
  }
};
