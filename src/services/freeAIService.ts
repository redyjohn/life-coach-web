// å…è²» AI æœå‹™é…ç½®
export interface FreeAIConfig {
  name: string
  endpoint: string
  apiKey?: string
  model: string
  maxTokens: number
  isAvailable: boolean
  priority: number // å„ªå…ˆç´šï¼Œæ•¸å­—è¶Šå°å„ªå…ˆç´šè¶Šé«˜
}

// å…è²» AI æœå‹™åˆ—è¡¨
export const freeAIServices: FreeAIConfig[] = [
  {
    name: 'Mock AI (æ¸¬è©¦ç”¨)',
    endpoint: 'http://localhost:3000/api/mock',
    model: 'mock-model',
    maxTokens: 1000,
    isAvailable: true,
    priority: 1
  },
  {
    name: 'Hugging Face',
    endpoint: 'https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium',
    model: 'microsoft/DialoGPT-medium',
    maxTokens: 1000,
    isAvailable: false, // éœ€è¦ API Key
    priority: 2
  },
  {
    name: 'Ollama Local',
    endpoint: 'http://localhost:11434/api/generate',
    model: 'llama2',
    maxTokens: 2000,
    isAvailable: false, // éœ€è¦æœ¬åœ°å®‰è£ Ollama
    priority: 3
  }
]

// å…è²» AI æœå‹™ç®¡ç†å™¨
export class FreeAIManager {
  private currentService: FreeAIConfig | null = null
  private fallbackToOpenAI = false

  constructor() {
    this.initializeServices()
  }

  // åˆå§‹åŒ–æœå‹™
  private initializeServices() {
    // æª¢æŸ¥å“ªäº›æœå‹™å¯ç”¨
    this.checkServiceAvailability()
  }

  // æª¢æŸ¥æœå‹™å¯ç”¨æ€§
  private async checkServiceAvailability() {
    for (const service of freeAIServices) {
      if (service.isAvailable) {
        try {
          await this.testService(service)
        } catch (error) {
          console.warn(`æœå‹™ ${service.name} ä¸å¯ç”¨:`, error)
          service.isAvailable = false
        }
      }
    }
  }

  // æ¸¬è©¦æœå‹™
  private async testService(service: FreeAIConfig): Promise<boolean> {
    // Mock AI æœå‹™ç¸½æ˜¯å¯ç”¨
    if (service.name === 'Mock AI (æ¸¬è©¦ç”¨)') {
      return true
    }
    
    try {
      const response = await fetch(service.endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...(service.apiKey && { 'Authorization': `Bearer ${service.apiKey}` })
        },
        body: JSON.stringify({
          inputs: 'Hello',
          parameters: {
            max_length: 50,
            temperature: 0.7
          }
        })
      })
      return response.ok
    } catch (error) {
      return false
    }
  }

  // ç²å–æœ€ä½³å¯ç”¨æœå‹™
  public getBestAvailableService(): FreeAIConfig | null {
    const availableServices = freeAIServices
      .filter(service => service.isAvailable)
      .sort((a, b) => a.priority - b.priority)

    return availableServices.length > 0 ? availableServices[0] : null
  }

  // ä½¿ç”¨å…è²» AI æœå‹™
  public async callFreeAI(prompt: string, systemPrompt: string): Promise<string> {
    const service = this.getBestAvailableService()
    
    if (!service) {
      throw new Error('æ²’æœ‰å¯ç”¨çš„å…è²» AI æœå‹™')
    }

    try {
      return await this.callService(service, prompt, systemPrompt)
    } catch (error) {
      console.error(`æœå‹™ ${service.name} èª¿ç”¨å¤±æ•—:`, error)
      service.isAvailable = false
      
      // å˜—è©¦ä¸‹ä¸€å€‹æœå‹™
      const nextService = this.getBestAvailableService()
      if (nextService) {
        return await this.callService(nextService, prompt, systemPrompt)
      }
      
      throw error
    }
  }

  // èª¿ç”¨å…·é«”æœå‹™
  private async callService(service: FreeAIConfig, prompt: string, systemPrompt: string): Promise<string> {
    switch (service.name) {
      case 'Mock AI (æ¸¬è©¦ç”¨)':
        return await this.callMockAI(service, prompt, systemPrompt)
      case 'Hugging Face':
        return await this.callHuggingFace(service, prompt, systemPrompt)
      case 'Ollama Local':
        return await this.callOllama(service, prompt, systemPrompt)
      default:
        throw new Error(`ä¸æ”¯æŒçš„æœå‹™: ${service.name}`)
    }
  }

  // Mock AI æœå‹™èª¿ç”¨ï¼ˆæ¸¬è©¦ç”¨ï¼‰
  private async callMockAI(service: FreeAIConfig, prompt: string, systemPrompt: string): Promise<string> {
    // æ¨¡æ“¬ API èª¿ç”¨å»¶é²
    await new Promise(resolve => setTimeout(resolve, 1000))
    
    // æ ¹æ“šå•é¡Œé¡å‹ç”Ÿæˆæ¨¡æ“¬å›æ‡‰
    const responses = {
      'å¡”ç¾…ç‰Œ': 'ğŸ”® æ ¹æ“šå¡”ç¾…ç‰Œçš„æŒ‡å¼•ï¼Œæ‚¨ç›®å‰æ­£è™•æ–¼ä¸€å€‹é‡è¦çš„è½‰æŠ˜é»ã€‚å»ºè­°æ‚¨ä¿æŒé–‹æ”¾çš„å¿ƒæ…‹ï¼Œç›¸ä¿¡è‡ªå·±çš„ç›´è¦ºï¼Œæ–°çš„æ©Ÿæœƒå³å°‡åˆ°ä¾†ã€‚',
      'æ„›æƒ…': 'ğŸ’• åœ¨æ„›æƒ…æ–¹é¢ï¼Œæ‚¨éœ€è¦æ›´å¤šçš„è€å¿ƒå’Œç†è§£ã€‚çœŸæ­£çš„æ„›æƒ…éœ€è¦æ™‚é–“ä¾†åŸ¹é¤Šï¼Œä¸è¦æ€¥æ–¼æ±‚æˆã€‚',
      'äº‹æ¥­': 'ğŸ’¼ æ‚¨çš„äº‹æ¥­ç™¼å±•å‰æ™¯è‰¯å¥½ï¼Œä½†éœ€è¦æ›´å¤šçš„åŠªåŠ›å’Œå°ˆæ³¨ã€‚å»ºè­°æ‚¨åˆ¶å®šæ˜ç¢ºçš„ç›®æ¨™ï¼Œä¸¦å …æŒä¸æ‡ˆåœ°è¿½æ±‚ã€‚',
      'å¥åº·': 'ğŸ¥ æ‚¨çš„å¥åº·ç‹€æ³æ•´é«”è‰¯å¥½ï¼Œä½†éœ€è¦æ³¨æ„ä¼‘æ¯å’Œé£²é£Ÿã€‚å»ºè­°æ‚¨ä¿æŒè¦å¾‹çš„ç”Ÿæ´»ä½œæ¯ï¼Œé©åº¦é‹å‹•ã€‚',
      'è²¡é‹': 'ğŸ’° æ‚¨çš„è²¡é‹æ­£åœ¨ä¸Šå‡ï¼Œä½†éœ€è¦è¬¹æ…ç†è²¡ã€‚å»ºè­°æ‚¨åˆ¶å®šåˆç†çš„æŠ•è³‡è¨ˆåŠƒï¼Œé¿å…è¡å‹•æ¶ˆè²»ã€‚',
      'tarot': 'ğŸ”® According to the tarot cards, you are at an important turning point. Keep an open mind and trust your intuition, new opportunities are coming.',
      'love': 'ğŸ’• In matters of love, you need more patience and understanding. True love takes time to develop, don\'t rush.',
      'career': 'ğŸ’¼ Your career prospects are good, but you need more effort and focus. Set clear goals and pursue them persistently.',
      'health': 'ğŸ¥ Your health is generally good, but pay attention to rest and diet. Maintain regular lifestyle and moderate exercise.',
      'money': 'ğŸ’° Your financial luck is rising, but be careful with money management. Make reasonable investment plans and avoid impulsive spending.'
    }
    
    // æ ¹æ“šæç¤ºè©å…§å®¹é¸æ“‡å›æ‡‰
    let response = 'ğŸ”® æ ¹æ“šå åœçš„çµæœï¼Œæ‚¨ç›®å‰çš„æƒ…æ³éœ€è¦æ›´å¤šçš„è€å¿ƒå’Œæ™ºæ…§ã€‚å»ºè­°æ‚¨ä¿æŒç©æ¥µçš„å¿ƒæ…‹ï¼Œç›¸ä¿¡ç¾å¥½çš„æœªä¾†å³å°‡åˆ°ä¾†ã€‚'
    
    for (const [keyword, mockResponse] of Object.entries(responses)) {
      if (prompt.toLowerCase().includes(keyword.toLowerCase()) || systemPrompt.toLowerCase().includes(keyword.toLowerCase())) {
        response = mockResponse
        break
      }
    }
    
    return response
  }

  // Hugging Face API èª¿ç”¨
  private async callHuggingFace(service: FreeAIConfig, prompt: string, systemPrompt: string): Promise<string> {
    const response = await fetch(service.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(service.apiKey && { 'Authorization': `Bearer ${service.apiKey}` })
      },
      body: JSON.stringify({
        inputs: `${systemPrompt}\n\n${prompt}`,
        parameters: {
          max_length: service.maxTokens,
          temperature: 0.7,
          do_sample: true
        }
      })
    })

    if (!response.ok) {
      throw new Error(`Hugging Face API éŒ¯èª¤: ${response.status}`)
    }

    const data = await response.json()
    return data[0]?.generated_text || 'ç„¡æ³•ç”Ÿæˆå›æ‡‰'
  }

  // Ollama æœ¬åœ° API èª¿ç”¨
  private async callOllama(service: FreeAIConfig, prompt: string, systemPrompt: string): Promise<string> {
    const response = await fetch(service.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: service.model,
        prompt: `${systemPrompt}\n\n${prompt}`,
        stream: false,
        options: {
          temperature: 0.7,
          num_predict: service.maxTokens
        }
      })
    })

    if (!response.ok) {
      throw new Error(`Ollama API éŒ¯èª¤: ${response.status}`)
    }

    const data = await response.json()
    return data.response || 'ç„¡æ³•ç”Ÿæˆå›æ‡‰'
  }

  // Groq API èª¿ç”¨
  private async callGroq(service: FreeAIConfig, prompt: string, systemPrompt: string): Promise<string> {
    const response = await fetch(service.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${service.apiKey}`
      },
      body: JSON.stringify({
        model: service.model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: prompt }
        ],
        max_tokens: service.maxTokens,
        temperature: 0.7
      })
    })

    if (!response.ok) {
      throw new Error(`Groq API éŒ¯èª¤: ${response.status}`)
    }

    const data = await response.json()
    return data.choices[0]?.message?.content || 'ç„¡æ³•ç”Ÿæˆå›æ‡‰'
  }

  // æª¢æŸ¥æ˜¯å¦æ‡‰è©²ä½¿ç”¨å…è²»æœå‹™
  public shouldUseFreeService(): boolean {
    // æª¢æŸ¥ OpenAI API é…é¡ç‹€æ…‹
    const hasQuota = this.checkOpenAIQuota()
    
    // å¦‚æœæœ‰å…è²»æœå‹™å¯ç”¨ä¸” OpenAI é…é¡ä¸è¶³ï¼Œå„ªå…ˆä½¿ç”¨å…è²»æœå‹™
    const hasFreeService = this.getBestAvailableService() !== null
    
    return hasFreeService && !hasQuota
  }

  // æª¢æŸ¥ OpenAI é…é¡ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
  private checkOpenAIQuota(): boolean {
    // é€™è£¡å¯ä»¥å¯¦ç¾æ›´è¤‡é›œçš„é…é¡æª¢æŸ¥é‚è¼¯
    // ç›®å‰ç°¡åŒ–ç‚ºæª¢æŸ¥ç’°å¢ƒè®Šé‡
    return !!process.env.OPENAI_API_KEY
  }
}

// å‰µå»ºå…¨å±€å¯¦ä¾‹
export const freeAIManager = new FreeAIManager()

// ç°¡åŒ–çš„å…è²» AI èª¿ç”¨å‡½æ•¸
export async function callFreeAI(prompt: string, systemPrompt: string): Promise<string> {
  try {
    return await freeAIManager.callFreeAI(prompt, systemPrompt)
  } catch (error) {
    console.error('å…è²» AI æœå‹™èª¿ç”¨å¤±æ•—:', error)
    throw new Error('å…è²» AI æœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦')
  }
}

// æª¢æŸ¥æ˜¯å¦æ‡‰è©²ä½¿ç”¨å…è²»æœå‹™
export function shouldUseFreeService(): boolean {
  return freeAIManager.shouldUseFreeService()
}
